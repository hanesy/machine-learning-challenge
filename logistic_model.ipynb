{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Necessary Upgrades\n",
    "Run the cells in this section to make sure you have the latest version of sklearn and joblib.\n",
    "\n",
    "Restart your kernel after installing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Update sklearn to prevent version mismatches\n",
    "# !pip install sklearn --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## install joblib. This will be used to save your model. \n",
    "# !pip install joblib\n",
    "## Restart your kernel after installing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the CSV and Perform Basic Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/exoplanet_data.csv\")\n",
    "# Drop the null columns where all values are null\n",
    "df = df.dropna(axis='columns', how='all')\n",
    "# Drop the null rows\n",
    "df = df.dropna()\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>koi_disposition</th>\n",
       "      <th>koi_fpflag_nt</th>\n",
       "      <th>koi_fpflag_ss</th>\n",
       "      <th>koi_fpflag_co</th>\n",
       "      <th>koi_fpflag_ec</th>\n",
       "      <th>koi_period</th>\n",
       "      <th>koi_time0bk</th>\n",
       "      <th>koi_impact</th>\n",
       "      <th>koi_duration</th>\n",
       "      <th>koi_depth</th>\n",
       "      <th>...</th>\n",
       "      <th>koi_teq</th>\n",
       "      <th>koi_insol</th>\n",
       "      <th>koi_model_snr</th>\n",
       "      <th>koi_tce_plnt_num</th>\n",
       "      <th>koi_steff</th>\n",
       "      <th>koi_slogg</th>\n",
       "      <th>koi_srad</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>koi_kepmag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54.418383</td>\n",
       "      <td>162.513840</td>\n",
       "      <td>0.586</td>\n",
       "      <td>4.50700</td>\n",
       "      <td>874.8</td>\n",
       "      <td>...</td>\n",
       "      <td>443</td>\n",
       "      <td>9.11</td>\n",
       "      <td>25.8</td>\n",
       "      <td>2</td>\n",
       "      <td>5455</td>\n",
       "      <td>4.467</td>\n",
       "      <td>0.927</td>\n",
       "      <td>291.93423</td>\n",
       "      <td>48.141651</td>\n",
       "      <td>15.347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.899140</td>\n",
       "      <td>175.850252</td>\n",
       "      <td>0.969</td>\n",
       "      <td>1.78220</td>\n",
       "      <td>10829.0</td>\n",
       "      <td>...</td>\n",
       "      <td>638</td>\n",
       "      <td>39.30</td>\n",
       "      <td>76.3</td>\n",
       "      <td>1</td>\n",
       "      <td>5853</td>\n",
       "      <td>4.544</td>\n",
       "      <td>0.868</td>\n",
       "      <td>297.00482</td>\n",
       "      <td>48.134129</td>\n",
       "      <td>15.436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.736952</td>\n",
       "      <td>170.307565</td>\n",
       "      <td>1.276</td>\n",
       "      <td>2.40641</td>\n",
       "      <td>8079.2</td>\n",
       "      <td>...</td>\n",
       "      <td>1395</td>\n",
       "      <td>891.96</td>\n",
       "      <td>505.6</td>\n",
       "      <td>1</td>\n",
       "      <td>5805</td>\n",
       "      <td>4.564</td>\n",
       "      <td>0.791</td>\n",
       "      <td>285.53461</td>\n",
       "      <td>48.285210</td>\n",
       "      <td>15.597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.525592</td>\n",
       "      <td>171.595550</td>\n",
       "      <td>0.701</td>\n",
       "      <td>1.65450</td>\n",
       "      <td>603.3</td>\n",
       "      <td>...</td>\n",
       "      <td>1406</td>\n",
       "      <td>926.16</td>\n",
       "      <td>40.9</td>\n",
       "      <td>1</td>\n",
       "      <td>6031</td>\n",
       "      <td>4.438</td>\n",
       "      <td>1.046</td>\n",
       "      <td>288.75488</td>\n",
       "      <td>48.226200</td>\n",
       "      <td>15.509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.134435</td>\n",
       "      <td>172.979370</td>\n",
       "      <td>0.762</td>\n",
       "      <td>3.14020</td>\n",
       "      <td>686.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1160</td>\n",
       "      <td>427.65</td>\n",
       "      <td>40.2</td>\n",
       "      <td>2</td>\n",
       "      <td>6046</td>\n",
       "      <td>4.486</td>\n",
       "      <td>0.972</td>\n",
       "      <td>296.28613</td>\n",
       "      <td>48.224670</td>\n",
       "      <td>15.714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  koi_disposition  koi_fpflag_nt  koi_fpflag_ss  koi_fpflag_co  koi_fpflag_ec  \\\n",
       "0       CONFIRMED              0              0              0              0   \n",
       "1  FALSE POSITIVE              0              1              0              0   \n",
       "2  FALSE POSITIVE              0              1              0              0   \n",
       "3       CONFIRMED              0              0              0              0   \n",
       "4       CONFIRMED              0              0              0              0   \n",
       "\n",
       "   koi_period  koi_time0bk  koi_impact  koi_duration  koi_depth  ...  koi_teq  \\\n",
       "0   54.418383   162.513840       0.586       4.50700      874.8  ...      443   \n",
       "1   19.899140   175.850252       0.969       1.78220    10829.0  ...      638   \n",
       "2    1.736952   170.307565       1.276       2.40641     8079.2  ...     1395   \n",
       "3    2.525592   171.595550       0.701       1.65450      603.3  ...     1406   \n",
       "4    4.134435   172.979370       0.762       3.14020      686.0  ...     1160   \n",
       "\n",
       "   koi_insol  koi_model_snr  koi_tce_plnt_num  koi_steff  koi_slogg  koi_srad  \\\n",
       "0       9.11           25.8                 2       5455      4.467     0.927   \n",
       "1      39.30           76.3                 1       5853      4.544     0.868   \n",
       "2     891.96          505.6                 1       5805      4.564     0.791   \n",
       "3     926.16           40.9                 1       6031      4.438     1.046   \n",
       "4     427.65           40.2                 2       6046      4.486     0.972   \n",
       "\n",
       "          ra        dec  koi_kepmag  \n",
       "0  291.93423  48.141651      15.347  \n",
       "1  297.00482  48.134129      15.436  \n",
       "2  285.53461  48.285210      15.597  \n",
       "3  288.75488  48.226200      15.509  \n",
       "4  296.28613  48.224670      15.714  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop the error columns\n",
    "df = df.loc[:, ~df.columns.str.contains('_err')]\n",
    "df.columns\n",
    "\n",
    "# column definitions is available at the end of this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select your features (columns) and y-variable.\n",
    "Column definitions are available at the end of this notebook.\n",
    "\n",
    "Use `koi_disposition` for the y values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[[\"koi_disposition\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test with a subset\n",
    "# selected_features = df[['koi_fpflag_nt', 'koi_prad', 'koi_teq', 'koi_srad']]\n",
    "\n",
    "# all the columns minus y\n",
    "selected_features = df.drop(columns=[\"koi_disposition\"])\n",
    "# selected_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(selected_features, y, random_state=42, stratify = y)\n",
    "# X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "\n",
    "Scale the data and perform some feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale your data\n",
    "\n",
    "X_standard_scaler = StandardScaler().fit(X_train)\n",
    "X_minmax_scaler = MinMaxScaler().fit(X_train)\n",
    "\n",
    "X_train_minmax_scaled = X_minmax_scaler.transform(X_train)\n",
    "X_test_minmax_scaled = X_minmax_scaler.transform(X_test)\n",
    "\n",
    "X_train_standard_scaled = X_standard_scaler.transform(X_train)\n",
    "X_test_standard_scaled = X_standard_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_minmax = LogisticRegression()\n",
    "logistic_minmax.fit(X_train_minmax_scaled, y_train)\n",
    "\n",
    "logistic_standard = LogisticRegression()\n",
    "logistic_standard.fit(X_train_standard_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minmax Training Data Score: 0.807743658210948\n",
      "Minmax Testing Data Score: 0.8163615560640732\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "     CANDIDATE       0.65      0.56      0.60       422\n",
      "     CONFIRMED       0.63      0.70      0.67       450\n",
      "FALSE POSITIVE       0.99      1.00      0.99       876\n",
      "\n",
      "      accuracy                           0.82      1748\n",
      "     macro avg       0.76      0.75      0.75      1748\n",
      "  weighted avg       0.81      0.82      0.81      1748\n",
      "\n",
      "---\n",
      "Standard Training Data Score: 0.822429906542056\n",
      "Standard Testing Data Score: 0.8289473684210527\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "     CANDIDATE       0.68      0.59      0.63       422\n",
      "     CONFIRMED       0.66      0.72      0.69       450\n",
      "FALSE POSITIVE       0.99      1.00      0.99       876\n",
      "\n",
      "      accuracy                           0.83      1748\n",
      "     macro avg       0.77      0.77      0.77      1748\n",
      "  weighted avg       0.83      0.83      0.83      1748\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Minmax Training Data Score: {logistic_minmax.score(X_train_minmax_scaled, y_train)}\")\n",
    "print(f\"Minmax Testing Data Score: {logistic_minmax.score(X_test_minmax_scaled, y_test)}\")\n",
    "\n",
    "minmax_predictions = logistic_minmax.predict(X_test_minmax_scaled)\n",
    "print(classification_report(y_test, minmax_predictions))\n",
    "\n",
    "print (\"---\")\n",
    "\n",
    "print(f\"Standard Training Data Score: {logistic_standard.score(X_train_standard_scaled, y_train)}\")\n",
    "print(f\"Standard Testing Data Score: {logistic_standard.score(X_test_standard_scaled, y_test)}\")\n",
    "\n",
    "standard_predictions = logistic_standard.predict(X_test_standard_scaled)\n",
    "print(classification_report(y_test, standard_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning\n",
    "\n",
    "Use `GridSearchCV` to tune the model's parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the GridSearchCV model\n",
    "\n",
    "param_grid = {'C': [1, 5, 10],\n",
    "              'penalty': [\"l1\", \"l2\"]}\n",
    "\n",
    "logistic_minmax_search = LogisticRegression()\n",
    "logistic_grid_minmax = GridSearchCV(logistic_minmax_search, param_grid, cv=5, verbose=2)\n",
    "\n",
    "logistic_standard_search = LogisticRegression()\n",
    "logistic_grid_standard = GridSearchCV(logistic_standard_search, param_grid, cv=5, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[CV] C=1, penalty=l1 .................................................\n",
      "[CV] .................................. C=1, penalty=l1, total=   0.0s\n",
      "[CV] C=1, penalty=l1 .................................................\n",
      "[CV] .................................. C=1, penalty=l1, total=   0.0s\n",
      "[CV] C=1, penalty=l1 .................................................\n",
      "[CV] .................................. C=1, penalty=l1, total=   0.0s\n",
      "[CV] C=1, penalty=l1 .................................................\n",
      "[CV] .................................. C=1, penalty=l1, total=   0.0s\n",
      "[CV] C=1, penalty=l1 .................................................\n",
      "[CV] .................................. C=1, penalty=l1, total=   0.0s\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[CV] .................................. C=1, penalty=l2, total=   0.1s\n",
      "[CV] C=1, penalty=l2 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................................. C=1, penalty=l2, total=   0.1s\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[CV] .................................. C=1, penalty=l2, total=   0.1s\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[CV] .................................. C=1, penalty=l2, total=   0.1s\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[CV] .................................. C=1, penalty=l2, total=   0.1s\n",
      "[CV] C=5, penalty=l1 .................................................\n",
      "[CV] .................................. C=5, penalty=l1, total=   0.0s\n",
      "[CV] C=5, penalty=l1 .................................................\n",
      "[CV] .................................. C=5, penalty=l1, total=   0.0s\n",
      "[CV] C=5, penalty=l1 .................................................\n",
      "[CV] .................................. C=5, penalty=l1, total=   0.0s\n",
      "[CV] C=5, penalty=l1 .................................................\n",
      "[CV] .................................. C=5, penalty=l1, total=   0.0s\n",
      "[CV] C=5, penalty=l1 .................................................\n",
      "[CV] .................................. C=5, penalty=l1, total=   0.0s\n",
      "[CV] C=5, penalty=l2 .................................................\n",
      "[CV] .................................. C=5, penalty=l2, total=   0.1s\n",
      "[CV] C=5, penalty=l2 .................................................\n",
      "[CV] .................................. C=5, penalty=l2, total=   0.1s\n",
      "[CV] C=5, penalty=l2 .................................................\n",
      "[CV] .................................. C=5, penalty=l2, total=   0.1s\n",
      "[CV] C=5, penalty=l2 .................................................\n",
      "[CV] .................................. C=5, penalty=l2, total=   0.1s\n",
      "[CV] C=5, penalty=l2 .................................................\n",
      "[CV] .................................. C=5, penalty=l2, total=   0.1s\n",
      "[CV] C=10, penalty=l1 ................................................\n",
      "[CV] ................................. C=10, penalty=l1, total=   0.0s\n",
      "[CV] C=10, penalty=l1 ................................................\n",
      "[CV] ................................. C=10, penalty=l1, total=   0.0s\n",
      "[CV] C=10, penalty=l1 ................................................\n",
      "[CV] ................................. C=10, penalty=l1, total=   0.0s\n",
      "[CV] C=10, penalty=l1 ................................................\n",
      "[CV] ................................. C=10, penalty=l1, total=   0.0s\n",
      "[CV] C=10, penalty=l1 ................................................\n",
      "[CV] ................................. C=10, penalty=l1, total=   0.0s\n",
      "[CV] C=10, penalty=l2 ................................................\n",
      "[CV] ................................. C=10, penalty=l2, total=   0.1s\n",
      "[CV] C=10, penalty=l2 ................................................\n",
      "[CV] ................................. C=10, penalty=l2, total=   0.1s\n",
      "[CV] C=10, penalty=l2 ................................................\n",
      "[CV] ................................. C=10, penalty=l2, total=   0.1s\n",
      "[CV] C=10, penalty=l2 ................................................\n",
      "[CV] ................................. C=10, penalty=l2, total=   0.1s\n",
      "[CV] C=10, penalty=l2 ................................................\n",
      "[CV] ................................. C=10, penalty=l2, total=   0.1s\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[CV] C=1, penalty=l1 .................................................\n",
      "[CV] .................................. C=1, penalty=l1, total=   0.0s\n",
      "[CV] C=1, penalty=l1 .................................................\n",
      "[CV] .................................. C=1, penalty=l1, total=   0.0s\n",
      "[CV] C=1, penalty=l1 .................................................\n",
      "[CV] .................................. C=1, penalty=l1, total=   0.0s\n",
      "[CV] C=1, penalty=l1 .................................................\n",
      "[CV] .................................. C=1, penalty=l1, total=   0.0s\n",
      "[CV] C=1, penalty=l1 .................................................\n",
      "[CV] .................................. C=1, penalty=l1, total=   0.0s\n",
      "[CV] C=1, penalty=l2 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................................. C=1, penalty=l2, total=   0.1s\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[CV] .................................. C=1, penalty=l2, total=   0.1s\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[CV] .................................. C=1, penalty=l2, total=   0.1s\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[CV] .................................. C=1, penalty=l2, total=   0.1s\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[CV] .................................. C=1, penalty=l2, total=   0.1s\n",
      "[CV] C=5, penalty=l1 .................................................\n",
      "[CV] .................................. C=5, penalty=l1, total=   0.0s\n",
      "[CV] C=5, penalty=l1 .................................................\n",
      "[CV] .................................. C=5, penalty=l1, total=   0.0s\n",
      "[CV] C=5, penalty=l1 .................................................\n",
      "[CV] .................................. C=5, penalty=l1, total=   0.0s\n",
      "[CV] C=5, penalty=l1 .................................................\n",
      "[CV] .................................. C=5, penalty=l1, total=   0.0s\n",
      "[CV] C=5, penalty=l1 .................................................\n",
      "[CV] .................................. C=5, penalty=l1, total=   0.0s\n",
      "[CV] C=5, penalty=l2 .................................................\n",
      "[CV] .................................. C=5, penalty=l2, total=   0.1s\n",
      "[CV] C=5, penalty=l2 .................................................\n",
      "[CV] .................................. C=5, penalty=l2, total=   0.1s\n",
      "[CV] C=5, penalty=l2 .................................................\n",
      "[CV] .................................. C=5, penalty=l2, total=   0.1s\n",
      "[CV] C=5, penalty=l2 .................................................\n",
      "[CV] .................................. C=5, penalty=l2, total=   0.1s\n",
      "[CV] C=5, penalty=l2 .................................................\n",
      "[CV] .................................. C=5, penalty=l2, total=   0.1s\n",
      "[CV] C=10, penalty=l1 ................................................\n",
      "[CV] ................................. C=10, penalty=l1, total=   0.0s\n",
      "[CV] C=10, penalty=l1 ................................................\n",
      "[CV] ................................. C=10, penalty=l1, total=   0.0s\n",
      "[CV] C=10, penalty=l1 ................................................\n",
      "[CV] ................................. C=10, penalty=l1, total=   0.0s\n",
      "[CV] C=10, penalty=l1 ................................................\n",
      "[CV] ................................. C=10, penalty=l1, total=   0.0s\n",
      "[CV] C=10, penalty=l1 ................................................\n",
      "[CV] ................................. C=10, penalty=l1, total=   0.0s\n",
      "[CV] C=10, penalty=l2 ................................................\n",
      "[CV] ................................. C=10, penalty=l2, total=   0.1s\n",
      "[CV] C=10, penalty=l2 ................................................\n",
      "[CV] ................................. C=10, penalty=l2, total=   0.1s\n",
      "[CV] C=10, penalty=l2 ................................................\n",
      "[CV] ................................. C=10, penalty=l2, total=   0.1s\n",
      "[CV] C=10, penalty=l2 ................................................\n",
      "[CV] ................................. C=10, penalty=l2, total=   0.1s\n",
      "[CV] C=10, penalty=l2 ................................................\n",
      "[CV] ................................. C=10, penalty=l2, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    1.6s finished\n"
     ]
    }
   ],
   "source": [
    "# Train the model with GridSearch\n",
    "best_logistic_model_minmax = logistic_grid_minmax.fit(X_train_minmax_scaled, y_train)\n",
    "best_logistic_model_standard = logistic_grid_standard.fit(X_train_standard_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minmax best params: {'C': 10, 'penalty': 'l2'}\n",
      "Minmax best score: 0.8104157722003507\n",
      "Minmax best best estimator: LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "---\n",
      "Standard best params: {'C': 10, 'penalty': 'l2'}\n",
      "Standard best score: 0.8224315778749662\n",
      "Standard best best estimator: LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Minmax best params: {best_logistic_model_minmax.best_params_}\")\n",
    "print(f\"Minmax best score: {best_logistic_model_minmax.best_score_}\")\n",
    "print(f\"Minmax best best estimator: {best_logistic_model_minmax.best_estimator_}\")\n",
    "print (\"---\")\n",
    "print(f\"Standard best params: {best_logistic_model_standard.best_params_}\")\n",
    "print(f\"Standard best score: {best_logistic_model_standard.best_score_}\")\n",
    "print(f\"Standard best best estimator: {best_logistic_model_standard.best_estimator_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minmax Training Data Score: 0.8148006866297921\n",
      "Minmax Testing Data Score: 0.8283752860411899\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "     CANDIDATE       0.68      0.59      0.63       422\n",
      "     CONFIRMED       0.66      0.72      0.69       450\n",
      "FALSE POSITIVE       0.99      1.00      0.99       876\n",
      "\n",
      "      accuracy                           0.83      1748\n",
      "     macro avg       0.77      0.77      0.77      1748\n",
      "  weighted avg       0.83      0.83      0.83      1748\n",
      "\n",
      "---\n",
      "Standard Training Data Score: 0.8247186725157353\n",
      "Standard Testing Data Score: 0.834096109839817\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "     CANDIDATE       0.69      0.60      0.65       422\n",
      "     CONFIRMED       0.66      0.73      0.70       450\n",
      "FALSE POSITIVE       0.99      1.00      0.99       876\n",
      "\n",
      "      accuracy                           0.83      1748\n",
      "     macro avg       0.78      0.78      0.78      1748\n",
      "  weighted avg       0.83      0.83      0.83      1748\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Minmax Training Data Score: {best_logistic_model_minmax.score(X_train_minmax_scaled, y_train)}\")\n",
    "print(f\"Minmax Testing Data Score: {best_logistic_model_minmax.score(X_test_minmax_scaled, y_test)}\")\n",
    "\n",
    "minmax_predictions = best_logistic_model_minmax.predict(X_test_minmax_scaled)\n",
    "print(classification_report(y_test, minmax_predictions))\n",
    "\n",
    "print (\"---\")\n",
    "\n",
    "print(f\"Standard Training Data Score: {best_logistic_model_standard.score(X_train_standard_scaled, y_train)}\")\n",
    "print(f\"Standard Testing Data Score: {best_logistic_model_standard.score(X_test_standard_scaled, y_test)}\")\n",
    "\n",
    "standard_predictions = best_logistic_model_standard.predict(X_test_standard_scaled)\n",
    "print(classification_report(y_test, standard_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>minmax scaler</th>\n",
       "      <th>standard scaler</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>CANDIDATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>CANDIDATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>CANDIDATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>CONFIRMED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>CANDIDATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>CANDIDATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>CANDIDATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>CONFIRMED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Actual   minmax scaler standard scaler\n",
       "0        CANDIDATE       CANDIDATE       CANDIDATE\n",
       "1   FALSE POSITIVE  FALSE POSITIVE  FALSE POSITIVE\n",
       "2   FALSE POSITIVE  FALSE POSITIVE  FALSE POSITIVE\n",
       "3   FALSE POSITIVE  FALSE POSITIVE  FALSE POSITIVE\n",
       "4        CANDIDATE       CONFIRMED       CANDIDATE\n",
       "5   FALSE POSITIVE  FALSE POSITIVE  FALSE POSITIVE\n",
       "6        CANDIDATE       CANDIDATE       CANDIDATE\n",
       "7   FALSE POSITIVE  FALSE POSITIVE  FALSE POSITIVE\n",
       "8   FALSE POSITIVE  FALSE POSITIVE  FALSE POSITIVE\n",
       "9   FALSE POSITIVE  FALSE POSITIVE  FALSE POSITIVE\n",
       "10  FALSE POSITIVE  FALSE POSITIVE  FALSE POSITIVE\n",
       "11  FALSE POSITIVE  FALSE POSITIVE  FALSE POSITIVE\n",
       "12       CONFIRMED       CONFIRMED       CONFIRMED\n",
       "13  FALSE POSITIVE  FALSE POSITIVE  FALSE POSITIVE\n",
       "14  FALSE POSITIVE  FALSE POSITIVE  FALSE POSITIVE\n",
       "15       CANDIDATE       CANDIDATE       CANDIDATE\n",
       "16       CANDIDATE       CANDIDATE       CANDIDATE\n",
       "17       CANDIDATE       CANDIDATE       CANDIDATE\n",
       "18       CANDIDATE       CANDIDATE       CONFIRMED\n",
       "19  FALSE POSITIVE  FALSE POSITIVE  FALSE POSITIVE"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see how it compares\n",
    "minmax_predicted = minmax_predictions[:20]\n",
    "standard_predicted = standard_predictions[:20]\n",
    "actual = y_test[\"koi_disposition\"][:20].tolist()\n",
    "pd.DataFrame({\"Actual\": actual, \"minmax scaler\": minmax_predicted, \"standard scaler\": standard_predicted}).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/logistic_standard.h5']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minmax_logistic = 'models/logistic_minmax.h5'\n",
    "joblib.dump(best_logistic_model_minmax, minmax_logistic)\n",
    "\n",
    "standard_logistic = 'models/logistic_standard.h5'\n",
    "joblib.dump(best_logistic_model_standard, standard_logistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8283752860411899\n",
      "0.834096109839817\n"
     ]
    }
   ],
   "source": [
    "loaded_model = joblib.load(\"models/logistic_minmax.h5\")\n",
    "print(f\"{loaded_model.score(X_test_minmax_scaled, y_test)}\")\n",
    "\n",
    "loaded_model = joblib.load(\"models/logistic_standard.h5\")\n",
    "print(f\"{loaded_model.score(X_test_standard_scaled, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Column Details\n",
    "\n",
    "### Exoplanet Archive Information\n",
    "* 'koi_disposition': The pipeline flag that designates the most probable physical explanation of the KOI\n",
    "\n",
    "### Project Disposition Columns\n",
    "* 'koi_fpflag_nt': A KOI whose light curve is not consistent with that of a transiting planet.\n",
    "* 'koi_fpflag_ss': A KOI that is observed to have a significant secondary event, transit shape, or out-of-eclipse variability, which indicates that the transit-like event is most likely caused by an eclipsing binary.\n",
    "* 'koi_fpflag_co': The source of the signal is from a nearby star, as inferred by measuring the centroid location of the image both in and out of transit, or by the strength of the transit signal in the target's outer (halo) pixels as compared to the transit signal from the pixels in the optimal (or core) aperture.\n",
    "* 'koi_fpflag_ec': The KOI shares the same period and epoch as another object and is judged to be the result of flux contamination in the aperture or electronic crosstalk.\n",
    "\n",
    "### Transit Properties\n",
    "Transit parameters delivered by the Kepler Project are typically best-fit parameters produced by a Mandel-Agol (2002) fit to a multi-quarter Kepler light curve, assuming a linear orbital ephemeris. Some of the parameters listed below are fit directly, other are derived from the best-fit parameters. Limb-darkening coefficients are fixed and pre-calculated from host star properties. Orbital Period, Transit Epoch, Planet-Star Radius Ratio, Planet-Star Distance over Star Radius and Impact Parameter are the free parameters in the fit. Matrix covariances are adopted as errors to the fit parameters; they therefore ignore the effects of correlation between the fit parameters and are likely to be underestimates.\n",
    "\n",
    "See the links in the Purpose of KOI document for each activity table for more details on the fits for each delivery.\n",
    "\n",
    "Scaled planetary parameters combine the dimensionless fit parameters with physical stellar parameters to produce planet characteristics in physical units.\n",
    "\n",
    "Best-fit planetary transit parameters are typically normalized to the size of the host star. Physical planet parameters may be derived by scaling to the star's size and temperature. Transit parameters also depend weakly upon the limb-darkening coefficients which are derived from the stellar parameters (e.g., Claret and Bloemen 2011).\n",
    "\n",
    "* 'koi_period': The interval between consecutive planetary transits.\n",
    "* 'koi_time0bk': The time corresponding to the center of the first detected transit in Barycentric Julian Day (BJD) minus a constant offset of 2,454,833.0 days. The offset corresponds to 12:00 on Jan 1, 2009 UTC.\n",
    "* 'koi_impact': The sky-projected distance between the center of the stellar disc and the center of the planet disc at conjunction, normalized by the stellar radius\n",
    "* 'koi_duration': The duration of the observed transits. Duration is measured from first contact between the planet and star until last contact. Contact times are typically computed from a best-fit model produced by a Mandel-Agol (2002) model fit to a multi-quarter Kepler light curve, assuming a linear orbital ephemeris.\n",
    "* 'koi_depth': The fraction of stellar flux lost at the minimum of the planetary transit. Transit depths are typically computed from a best-fit model produced by a Mandel-Agol (2002) model fit to a multi-quarter Kepler light curve, assuming a linear orbital ephemeris.\n",
    "* 'koi_prad': The radius of the planet. Planetary radius is the product of the planet star radius ratio and the stellar radius.\n",
    "* 'koi_teq': Approximation for the temperature of the planet. \n",
    "* 'koi_insol': Insolation flux is another way to give the equilibrium temperature.\n",
    "\n",
    "### Threshold-Crossing Event (TCE) Information\n",
    "The Transiting Planet Search (TPS) module of the Kepler data analysis pipeline performs a detection test for planet transits in the multi-quarter, gap-filled flux time series. The TPS module detrends each quarterly PDC light curve to remove edge effects around data gaps and then combines the data segments together, filling gaps with interpolated data so as to condition the flux time series for a matched filter. The module applies an adaptive, wavelet-based matched filter (Jenkins 2002, Jenkins et al. 2010 and Tenenbaum et al. (2012)) to perform a joint characterization of observation noise and detection of transit-like features in the light curve.\n",
    "\n",
    "The TPS module estimates the Power Spectral Density of the flux time series as a function in time. This provides coefficients for a whitening filter to accommodate non-stationary, non-white noise and yields Single Event Statistic (SES) time series components. These can be interpreted as measurements of the statistical significance of the presence of a transit of trial duration at each point in the time series.\n",
    "\n",
    "Single Event Statistics are folded at each trial orbital period and the maximum Multiple Event Statistic (MES) is obtained over all trial periods and phases. The MES estimates the signal to noise ratio of the putative transit-like sequence against the measurement noise. The MES threshold for defining the sample of Threshold Crossing Events (TCEs) is provided within the Release Notes. For reference, a lower MES threshold of 7.1Ïƒ limits the number of false positives in the TCE sample due to statistical random noise to less than 1 over the primary mission (Jenkins, Caldwell and Borucki 2002).\n",
    "\n",
    "* 'koi_model_snr': Transit depth normalized by the mean uncertainty in the flux during the transits.\n",
    "* 'koi_tce_plnt_num': TCE Planet Number federated to the KOI.\n",
    "\n",
    "### Stellar Parameters\n",
    "Stellar effective temperature, surface gravity, metallicity, radius, mass, and age should comprise a consistent set. Associated error estimates are 1-Ïƒ uncertainties.\n",
    "\n",
    "* 'koi_steff': The photospheric temperature of the star.\n",
    "* 'koi_slogg': The base-10 logarithm of the acceleration due to gravity at the surface of the star.\n",
    "* 'koi_srad': The photospheric radius of the star\n",
    "\n",
    "### KIC Parameters\n",
    "* 'ra': KIC Right Ascension\n",
    "* 'dec': KIC Declination\n",
    "* 'koi_kepmag': Kepler-band (mag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "dev"
  },
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit ('PythonData': conda)",
   "language": "python",
   "name": "python37564bitpythondataconda93b4aacbe3a94029a49f9aca4966340b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
