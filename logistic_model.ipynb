{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Necessary Upgrades\n",
    "Run the cells in this section to make sure you have the latest version of sklearn and joblib.\n",
    "\n",
    "Restart your kernel after installing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Update sklearn to prevent version mismatches\n",
    "# !pip install sklearn --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## install joblib. This will be used to save your model. \n",
    "# !pip install joblib\n",
    "## Restart your kernel after installing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the CSV and Perform Basic Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/exoplanet_data.csv\")\n",
    "# Drop the null columns where all values are null\n",
    "df = df.dropna(axis='columns', how='all')\n",
    "# Drop the null rows\n",
    "df = df.dropna()\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['koi_disposition', 'koi_fpflag_nt', 'koi_fpflag_ss', 'koi_fpflag_co',\n",
       "       'koi_fpflag_ec', 'koi_period', 'koi_time0bk', 'koi_impact',\n",
       "       'koi_duration', 'koi_depth', 'koi_prad', 'koi_teq', 'koi_insol',\n",
       "       'koi_model_snr', 'koi_tce_plnt_num', 'koi_steff', 'koi_slogg',\n",
       "       'koi_srad', 'ra', 'dec', 'koi_kepmag'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop the error columns\n",
    "df = df.loc[:, ~df.columns.str.contains('_err')]\n",
    "df.columns\n",
    "\n",
    "# column definitions is available at the end of this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select your features (columns) and y-variable.\n",
    "Column definitions are available at the end of this notebook.\n",
    "\n",
    "Use `koi_disposition` for the y values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_binary = pd.get_dummies(df[\"koi_disposition\"])\n",
    "y = y_binary[\"CONFIRMED\"].values.reshape(-1, 1)\n",
    "# print(X.shape, y.shape)\n",
    "# y_binary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set features. This will also be used as your x values.\n",
    "selected_features = df[['koi_fpflag_nt', 'koi_prad', 'koi_teq', 'koi_srad']]\n",
    "# selected_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(selected_features, y, random_state=42)\n",
    "# X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "\n",
    "Scale the data using the MinMaxScaler and perform some feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale your data\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_model = LogisticRegression()\n",
    "logistic_model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.7488079343887087\n",
      "Testing Data Score: 0.7219679633867276\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Data Score: {logistic_model.score(X_train_scaled, y_train)}\")\n",
    "print(f\"Testing Data Score: {logistic_model.score(X_test_scaled, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      1.00      0.84      1264\n",
      "           1       0.00      0.00      0.00       484\n",
      "\n",
      "    accuracy                           0.72      1748\n",
      "   macro avg       0.36      0.50      0.42      1748\n",
      "weighted avg       0.52      0.72      0.61      1748\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = logistic_model.predict(X_test_scaled)\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning\n",
    "\n",
    "Use `GridSearchCV` to tune the model's parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the GridSearchCV model\n",
    "\n",
    "# Create regularization penalty space\n",
    "penalty = ['l1', 'l2']\n",
    "\n",
    "# Create regularization hyperparameter space\n",
    "C = np.logspace(0, 4, 10)\n",
    "\n",
    "# Create hyperparameter options\n",
    "hyperparameters = dict(C=C, penalty=penalty)\n",
    "\n",
    "logistic_grid = GridSearchCV(logistic_model, hyperparameters, cv=5, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV] C=1.0, penalty=l1 ...............................................\n",
      "[CV] ................................ C=1.0, penalty=l1, total=   0.0s\n",
      "[CV] C=1.0, penalty=l1 ...............................................\n",
      "[CV] ................................ C=1.0, penalty=l1, total=   0.0s\n",
      "[CV] C=1.0, penalty=l1 ...............................................\n",
      "[CV] ................................ C=1.0, penalty=l1, total=   0.0s\n",
      "[CV] C=1.0, penalty=l1 ...............................................\n",
      "[CV] ................................ C=1.0, penalty=l1, total=   0.0s\n",
      "[CV] C=1.0, penalty=l1 ...............................................\n",
      "[CV] ................................ C=1.0, penalty=l1, total=   0.0s\n",
      "[CV] C=1.0, penalty=l2 ...............................................\n",
      "[CV] ................................ C=1.0, penalty=l2, total=   0.0s\n",
      "[CV] C=1.0, penalty=l2 ...............................................\n",
      "[CV] ................................ C=1.0, penalty=l2, total=   0.0s\n",
      "[CV] C=1.0, penalty=l2 ...............................................\n",
      "[CV] ................................ C=1.0, penalty=l2, total=   0.0s\n",
      "[CV] C=1.0, penalty=l2 ...............................................\n",
      "[CV] ................................ C=1.0, penalty=l2, total=   0.0s\n",
      "[CV] C=1.0, penalty=l2 ...............................................\n",
      "[CV] ................................ C=1.0, penalty=l2, total=   0.0s\n",
      "[CV] C=2.7825594022071245, penalty=l1 ................................\n",
      "[CV] ................. C=2.7825594022071245, penalty=l1, total=   0.0s\n",
      "[CV] C=2.7825594022071245, penalty=l1 ................................\n",
      "[CV] ................. C=2.7825594022071245, penalty=l1, total=   0.0s\n",
      "[CV] C=2.7825594022071245, penalty=l1 ................................\n",
      "[CV] ................. C=2.7825594022071245, penalty=l1, total=   0.0s\n",
      "[CV] C=2.7825594022071245, penalty=l1 ................................\n",
      "[CV] ................. C=2.7825594022071245, penalty=l1, total=   0.0s\n",
      "[CV] C=2.7825594022071245, penalty=l1 ................................\n",
      "[CV] ................. C=2.7825594022071245, penalty=l1, total=   0.0s\n",
      "[CV] C=2.7825594022071245, penalty=l2 ................................\n",
      "[CV] ................. C=2.7825594022071245, penalty=l2, total=   0.0s\n",
      "[CV] C=2.7825594022071245, penalty=l2 ................................\n",
      "[CV] ................. C=2.7825594022071245, penalty=l2, total=   0.0s\n",
      "[CV] C=2.7825594022071245, penalty=l2 ................................\n",
      "[CV] ................. C=2.7825594022071245, penalty=l2, total=   0.0s\n",
      "[CV] C=2.7825594022071245, penalty=l2 ................................\n",
      "[CV] ................. C=2.7825594022071245, penalty=l2, total=   0.0s\n",
      "[CV] C=2.7825594022071245, penalty=l2 ................................\n",
      "[CV] ................. C=2.7825594022071245, penalty=l2, total=   0.0s\n",
      "[CV] C=7.742636826811269, penalty=l1 .................................\n",
      "[CV] .................. C=7.742636826811269, penalty=l1, total=   0.0s\n",
      "[CV] C=7.742636826811269, penalty=l1 .................................\n",
      "[CV] .................. C=7.742636826811269, penalty=l1, total=   0.0s\n",
      "[CV] C=7.742636826811269, penalty=l1 .................................\n",
      "[CV] .................. C=7.742636826811269, penalty=l1, total=   0.0s\n",
      "[CV] C=7.742636826811269, penalty=l1 .................................\n",
      "[CV] .................. C=7.742636826811269, penalty=l1, total=   0.0s\n",
      "[CV] C=7.742636826811269, penalty=l1 .................................\n",
      "[CV] .................. C=7.742636826811269, penalty=l1, total=   0.0s\n",
      "[CV] C=7.742636826811269, penalty=l2 .................................\n",
      "[CV] .................. C=7.742636826811269, penalty=l2, total=   0.0s\n",
      "[CV] C=7.742636826811269, penalty=l2 .................................\n",
      "[CV] .................. C=7.742636826811269, penalty=l2, total=   0.0s\n",
      "[CV] C=7.742636826811269, penalty=l2 .................................\n",
      "[CV] .................. C=7.742636826811269, penalty=l2, total=   0.0s\n",
      "[CV] C=7.742636826811269, penalty=l2 .................................\n",
      "[CV] .................. C=7.742636826811269, penalty=l2, total=   0.0s\n",
      "[CV] C=7.742636826811269, penalty=l2 .................................\n",
      "[CV] .................. C=7.742636826811269, penalty=l2, total=   0.0s\n",
      "[CV] C=21.544346900318832, penalty=l1 ................................\n",
      "[CV] ................. C=21.544346900318832, penalty=l1, total=   0.0s\n",
      "[CV] C=21.544346900318832, penalty=l1 ................................\n",
      "[CV] ................. C=21.544346900318832, penalty=l1, total=   0.0s\n",
      "[CV] C=21.544346900318832, penalty=l1 ................................\n",
      "[CV] ................. C=21.544346900318832, penalty=l1, total=   0.0s\n",
      "[CV] C=21.544346900318832, penalty=l1 ................................\n",
      "[CV] ................. C=21.544346900318832, penalty=l1, total=   0.0s\n",
      "[CV] C=21.544346900318832, penalty=l1 ................................\n",
      "[CV] ................. C=21.544346900318832, penalty=l1, total=   0.0s\n",
      "[CV] C=21.544346900318832, penalty=l2 ................................\n",
      "[CV] ................. C=21.544346900318832, penalty=l2, total=   0.0s\n",
      "[CV] C=21.544346900318832, penalty=l2 ................................\n",
      "[CV] ................. C=21.544346900318832, penalty=l2, total=   0.0s\n",
      "[CV] C=21.544346900318832, penalty=l2 ................................\n",
      "[CV] ................. C=21.544346900318832, penalty=l2, total=   0.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] C=21.544346900318832, penalty=l2 ................................\n",
      "[CV] ................. C=21.544346900318832, penalty=l2, total=   0.0s\n",
      "[CV] C=21.544346900318832, penalty=l2 ................................\n",
      "[CV] ................. C=21.544346900318832, penalty=l2, total=   0.0s\n",
      "[CV] C=59.94842503189409, penalty=l1 .................................\n",
      "[CV] .................. C=59.94842503189409, penalty=l1, total=   0.0s\n",
      "[CV] C=59.94842503189409, penalty=l1 .................................\n",
      "[CV] .................. C=59.94842503189409, penalty=l1, total=   0.0s\n",
      "[CV] C=59.94842503189409, penalty=l1 .................................\n",
      "[CV] .................. C=59.94842503189409, penalty=l1, total=   0.0s\n",
      "[CV] C=59.94842503189409, penalty=l1 .................................\n",
      "[CV] .................. C=59.94842503189409, penalty=l1, total=   0.0s\n",
      "[CV] C=59.94842503189409, penalty=l1 .................................\n",
      "[CV] .................. C=59.94842503189409, penalty=l1, total=   0.0s\n",
      "[CV] C=59.94842503189409, penalty=l2 .................................\n",
      "[CV] .................. C=59.94842503189409, penalty=l2, total=   0.0s\n",
      "[CV] C=59.94842503189409, penalty=l2 .................................\n",
      "[CV] .................. C=59.94842503189409, penalty=l2, total=   0.0s\n",
      "[CV] C=59.94842503189409, penalty=l2 .................................\n",
      "[CV] .................. C=59.94842503189409, penalty=l2, total=   0.0s\n",
      "[CV] C=59.94842503189409, penalty=l2 .................................\n",
      "[CV] .................. C=59.94842503189409, penalty=l2, total=   0.0s\n",
      "[CV] C=59.94842503189409, penalty=l2 .................................\n",
      "[CV] .................. C=59.94842503189409, penalty=l2, total=   0.0s\n",
      "[CV] C=166.81005372000593, penalty=l1 ................................\n",
      "[CV] ................. C=166.81005372000593, penalty=l1, total=   0.0s\n",
      "[CV] C=166.81005372000593, penalty=l1 ................................\n",
      "[CV] ................. C=166.81005372000593, penalty=l1, total=   0.0s\n",
      "[CV] C=166.81005372000593, penalty=l1 ................................\n",
      "[CV] ................. C=166.81005372000593, penalty=l1, total=   0.0s\n",
      "[CV] C=166.81005372000593, penalty=l1 ................................\n",
      "[CV] ................. C=166.81005372000593, penalty=l1, total=   0.0s\n",
      "[CV] C=166.81005372000593, penalty=l1 ................................\n",
      "[CV] ................. C=166.81005372000593, penalty=l1, total=   0.0s\n",
      "[CV] C=166.81005372000593, penalty=l2 ................................\n",
      "[CV] ................. C=166.81005372000593, penalty=l2, total=   0.0s\n",
      "[CV] C=166.81005372000593, penalty=l2 ................................\n",
      "[CV] ................. C=166.81005372000593, penalty=l2, total=   0.0s\n",
      "[CV] C=166.81005372000593, penalty=l2 ................................\n",
      "[CV] ................. C=166.81005372000593, penalty=l2, total=   0.0s\n",
      "[CV] C=166.81005372000593, penalty=l2 ................................\n",
      "[CV] ................. C=166.81005372000593, penalty=l2, total=   0.0s\n",
      "[CV] C=166.81005372000593, penalty=l2 ................................\n",
      "[CV] ................. C=166.81005372000593, penalty=l2, total=   0.0s\n",
      "[CV] C=464.15888336127773, penalty=l1 ................................\n",
      "[CV] ................. C=464.15888336127773, penalty=l1, total=   0.0s\n",
      "[CV] C=464.15888336127773, penalty=l1 ................................\n",
      "[CV] ................. C=464.15888336127773, penalty=l1, total=   0.0s\n",
      "[CV] C=464.15888336127773, penalty=l1 ................................\n",
      "[CV] ................. C=464.15888336127773, penalty=l1, total=   0.0s\n",
      "[CV] C=464.15888336127773, penalty=l1 ................................\n",
      "[CV] ................. C=464.15888336127773, penalty=l1, total=   0.0s\n",
      "[CV] C=464.15888336127773, penalty=l1 ................................\n",
      "[CV] ................. C=464.15888336127773, penalty=l1, total=   0.0s\n",
      "[CV] C=464.15888336127773, penalty=l2 ................................\n",
      "[CV] ................. C=464.15888336127773, penalty=l2, total=   0.0s\n",
      "[CV] C=464.15888336127773, penalty=l2 ................................\n",
      "[CV] ................. C=464.15888336127773, penalty=l2, total=   0.0s\n",
      "[CV] C=464.15888336127773, penalty=l2 ................................\n",
      "[CV] ................. C=464.15888336127773, penalty=l2, total=   0.0s\n",
      "[CV] C=464.15888336127773, penalty=l2 ................................\n",
      "[CV] ................. C=464.15888336127773, penalty=l2, total=   0.0s\n",
      "[CV] C=464.15888336127773, penalty=l2 ................................\n",
      "[CV] ................. C=464.15888336127773, penalty=l2, total=   0.0s\n",
      "[CV] C=1291.5496650148827, penalty=l1 ................................\n",
      "[CV] ................. C=1291.5496650148827, penalty=l1, total=   0.0s\n",
      "[CV] C=1291.5496650148827, penalty=l1 ................................\n",
      "[CV] ................. C=1291.5496650148827, penalty=l1, total=   0.0s\n",
      "[CV] C=1291.5496650148827, penalty=l1 ................................\n",
      "[CV] ................. C=1291.5496650148827, penalty=l1, total=   0.0s\n",
      "[CV] C=1291.5496650148827, penalty=l1 ................................\n",
      "[CV] ................. C=1291.5496650148827, penalty=l1, total=   0.0s\n",
      "[CV] C=1291.5496650148827, penalty=l1 ................................\n",
      "[CV] ................. C=1291.5496650148827, penalty=l1, total=   0.0s\n",
      "[CV] C=1291.5496650148827, penalty=l2 ................................\n",
      "[CV] ................. C=1291.5496650148827, penalty=l2, total=   0.0s\n",
      "[CV] C=1291.5496650148827, penalty=l2 ................................\n",
      "[CV] ................. C=1291.5496650148827, penalty=l2, total=   0.0s\n",
      "[CV] C=1291.5496650148827, penalty=l2 ................................\n",
      "[CV] ................. C=1291.5496650148827, penalty=l2, total=   0.0s\n",
      "[CV] C=1291.5496650148827, penalty=l2 ................................\n",
      "[CV] ................. C=1291.5496650148827, penalty=l2, total=   0.0s\n",
      "[CV] C=1291.5496650148827, penalty=l2 ................................\n",
      "[CV] ................. C=1291.5496650148827, penalty=l2, total=   0.0s\n",
      "[CV] C=3593.813663804626, penalty=l1 .................................\n",
      "[CV] .................. C=3593.813663804626, penalty=l1, total=   0.0s\n",
      "[CV] C=3593.813663804626, penalty=l1 .................................\n",
      "[CV] .................. C=3593.813663804626, penalty=l1, total=   0.0s\n",
      "[CV] C=3593.813663804626, penalty=l1 .................................\n",
      "[CV] .................. C=3593.813663804626, penalty=l1, total=   0.0s\n",
      "[CV] C=3593.813663804626, penalty=l1 .................................\n",
      "[CV] .................. C=3593.813663804626, penalty=l1, total=   0.0s\n",
      "[CV] C=3593.813663804626, penalty=l1 .................................\n",
      "[CV] .................. C=3593.813663804626, penalty=l1, total=   0.0s\n",
      "[CV] C=3593.813663804626, penalty=l2 .................................\n",
      "[CV] .................. C=3593.813663804626, penalty=l2, total=   0.0s\n",
      "[CV] C=3593.813663804626, penalty=l2 .................................\n",
      "[CV] .................. C=3593.813663804626, penalty=l2, total=   0.0s\n",
      "[CV] C=3593.813663804626, penalty=l2 .................................\n",
      "[CV] .................. C=3593.813663804626, penalty=l2, total=   0.0s\n",
      "[CV] C=3593.813663804626, penalty=l2 .................................\n",
      "[CV] .................. C=3593.813663804626, penalty=l2, total=   0.0s\n",
      "[CV] C=3593.813663804626, penalty=l2 .................................\n",
      "[CV] .................. C=3593.813663804626, penalty=l2, total=   0.0s\n",
      "[CV] C=10000.0, penalty=l1 ...........................................\n",
      "[CV] ............................ C=10000.0, penalty=l1, total=   0.0s\n",
      "[CV] C=10000.0, penalty=l1 ...........................................\n",
      "[CV] ............................ C=10000.0, penalty=l1, total=   0.0s\n",
      "[CV] C=10000.0, penalty=l1 ...........................................\n",
      "[CV] ............................ C=10000.0, penalty=l1, total=   0.0s\n",
      "[CV] C=10000.0, penalty=l1 ...........................................\n",
      "[CV] ............................ C=10000.0, penalty=l1, total=   0.0s\n",
      "[CV] C=10000.0, penalty=l1 ...........................................\n",
      "[CV] ............................ C=10000.0, penalty=l1, total=   0.0s\n",
      "[CV] C=10000.0, penalty=l2 ...........................................\n",
      "[CV] ............................ C=10000.0, penalty=l2, total=   0.0s\n",
      "[CV] C=10000.0, penalty=l2 ...........................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............................ C=10000.0, penalty=l2, total=   0.0s\n",
      "[CV] C=10000.0, penalty=l2 ...........................................\n",
      "[CV] ............................ C=10000.0, penalty=l2, total=   0.0s\n",
      "[CV] C=10000.0, penalty=l2 ...........................................\n",
      "[CV] ............................ C=10000.0, penalty=l2, total=   0.0s\n",
      "[CV] C=10000.0, penalty=l2 ...........................................\n",
      "[CV] ............................ C=10000.0, penalty=l2, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.5s finished\n"
     ]
    }
   ],
   "source": [
    "# Train the model with GridSearch\n",
    "best_logistic_model = logistic_grid.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1.0, 'penalty': 'l2'}\n",
      "0.7488080250911446\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "print(logistic_grid.best_params_)\n",
    "print(logistic_grid.best_score_)\n",
    "print(logistic_grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predictions</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Predictions Actual\n",
       "0             0    [0]\n",
       "1             0    [0]\n",
       "2             0    [0]\n",
       "3             0    [0]\n",
       "4             0    [0]\n",
       "5             0    [1]\n",
       "6             0    [0]\n",
       "7             0    [0]\n",
       "8             0    [0]\n",
       "9             0    [0]\n",
       "10            0    [1]\n",
       "11            0    [1]\n",
       "12            0    [1]\n",
       "13            0    [0]\n",
       "14            0    [0]\n",
       "15            0    [0]\n",
       "16            0    [0]\n",
       "17            0    [0]\n",
       "18            0    [1]\n",
       "19            0    [1]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = logistic_grid.predict(X_test_scaled)\n",
    "predicted = predictions[:20]\n",
    "actual = y_test[:20].tolist()\n",
    "pd.DataFrame({\"Predictions\": predicted, \"Actual\": actual}).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      1.00      0.84      1264\n",
      "           1       0.00      0.00      0.00       484\n",
      "\n",
      "    accuracy                           0.72      1748\n",
      "   macro avg       0.36      0.50      0.42      1748\n",
      "weighted avg       0.52      0.72      0.61      1748\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score (Best): 0.7488079343887087\n",
      "Testing Data Score (Best): 0.7219679633867276\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Data Score (Best): {best_logistic_model.score(X_train_scaled, y_train)}\")\n",
    "print(f\"Testing Data Score (Best): {best_logistic_model.score(X_test_scaled, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['logistic_model.h5']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'logistic_model.h5'\n",
    "joblib.dump(best_logistic_model, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7219679633867276"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = joblib.load(\"logistic_model.h5\")\n",
    "loaded_model.score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Column Details\n",
    "\n",
    "### Exoplanet Archive Information\n",
    "* 'koi_disposition': The pipeline flag that designates the most probable physical explanation of the KOI\n",
    "\n",
    "### Project Disposition Columns\n",
    "* 'koi_fpflag_nt': A KOI whose light curve is not consistent with that of a transiting planet.\n",
    "* 'koi_fpflag_ss': A KOI that is observed to have a significant secondary event, transit shape, or out-of-eclipse variability, which indicates that the transit-like event is most likely caused by an eclipsing binary.\n",
    "* 'koi_fpflag_co': The source of the signal is from a nearby star, as inferred by measuring the centroid location of the image both in and out of transit, or by the strength of the transit signal in the target's outer (halo) pixels as compared to the transit signal from the pixels in the optimal (or core) aperture.\n",
    "* 'koi_fpflag_ec': The KOI shares the same period and epoch as another object and is judged to be the result of flux contamination in the aperture or electronic crosstalk.\n",
    "\n",
    "### Transit Properties\n",
    "Transit parameters delivered by the Kepler Project are typically best-fit parameters produced by a Mandel-Agol (2002) fit to a multi-quarter Kepler light curve, assuming a linear orbital ephemeris. Some of the parameters listed below are fit directly, other are derived from the best-fit parameters. Limb-darkening coefficients are fixed and pre-calculated from host star properties. Orbital Period, Transit Epoch, Planet-Star Radius Ratio, Planet-Star Distance over Star Radius and Impact Parameter are the free parameters in the fit. Matrix covariances are adopted as errors to the fit parameters; they therefore ignore the effects of correlation between the fit parameters and are likely to be underestimates.\n",
    "\n",
    "See the links in the Purpose of KOI document for each activity table for more details on the fits for each delivery.\n",
    "\n",
    "Scaled planetary parameters combine the dimensionless fit parameters with physical stellar parameters to produce planet characteristics in physical units.\n",
    "\n",
    "Best-fit planetary transit parameters are typically normalized to the size of the host star. Physical planet parameters may be derived by scaling to the star's size and temperature. Transit parameters also depend weakly upon the limb-darkening coefficients which are derived from the stellar parameters (e.g., Claret and Bloemen 2011).\n",
    "\n",
    "* 'koi_period': The interval between consecutive planetary transits.\n",
    "* 'koi_time0bk': The time corresponding to the center of the first detected transit in Barycentric Julian Day (BJD) minus a constant offset of 2,454,833.0 days. The offset corresponds to 12:00 on Jan 1, 2009 UTC.\n",
    "* 'koi_impact': The sky-projected distance between the center of the stellar disc and the center of the planet disc at conjunction, normalized by the stellar radius\n",
    "* 'koi_duration': The duration of the observed transits. Duration is measured from first contact between the planet and star until last contact. Contact times are typically computed from a best-fit model produced by a Mandel-Agol (2002) model fit to a multi-quarter Kepler light curve, assuming a linear orbital ephemeris.\n",
    "* 'koi_depth': The fraction of stellar flux lost at the minimum of the planetary transit. Transit depths are typically computed from a best-fit model produced by a Mandel-Agol (2002) model fit to a multi-quarter Kepler light curve, assuming a linear orbital ephemeris.\n",
    "* 'koi_prad': The radius of the planet. Planetary radius is the product of the planet star radius ratio and the stellar radius.\n",
    "* 'koi_teq': Approximation for the temperature of the planet. \n",
    "* 'koi_insol': Insolation flux is another way to give the equilibrium temperature.\n",
    "\n",
    "### Threshold-Crossing Event (TCE) Information\n",
    "The Transiting Planet Search (TPS) module of the Kepler data analysis pipeline performs a detection test for planet transits in the multi-quarter, gap-filled flux time series. The TPS module detrends each quarterly PDC light curve to remove edge effects around data gaps and then combines the data segments together, filling gaps with interpolated data so as to condition the flux time series for a matched filter. The module applies an adaptive, wavelet-based matched filter (Jenkins 2002, Jenkins et al. 2010 and Tenenbaum et al. (2012)) to perform a joint characterization of observation noise and detection of transit-like features in the light curve.\n",
    "\n",
    "The TPS module estimates the Power Spectral Density of the flux time series as a function in time. This provides coefficients for a whitening filter to accommodate non-stationary, non-white noise and yields Single Event Statistic (SES) time series components. These can be interpreted as measurements of the statistical significance of the presence of a transit of trial duration at each point in the time series.\n",
    "\n",
    "Single Event Statistics are folded at each trial orbital period and the maximum Multiple Event Statistic (MES) is obtained over all trial periods and phases. The MES estimates the signal to noise ratio of the putative transit-like sequence against the measurement noise. The MES threshold for defining the sample of Threshold Crossing Events (TCEs) is provided within the Release Notes. For reference, a lower MES threshold of 7.1σ limits the number of false positives in the TCE sample due to statistical random noise to less than 1 over the primary mission (Jenkins, Caldwell and Borucki 2002).\n",
    "\n",
    "* 'koi_model_snr': Transit depth normalized by the mean uncertainty in the flux during the transits.\n",
    "* 'koi_tce_plnt_num': TCE Planet Number federated to the KOI.\n",
    "\n",
    "### Stellar Parameters\n",
    "Stellar effective temperature, surface gravity, metallicity, radius, mass, and age should comprise a consistent set. Associated error estimates are 1-σ uncertainties.\n",
    "\n",
    "* 'koi_steff': The photospheric temperature of the star.\n",
    "* 'koi_slogg': The base-10 logarithm of the acceleration due to gravity at the surface of the star.\n",
    "* 'koi_srad': The photospheric radius of the star\n",
    "\n",
    "### KIC Parameters\n",
    "* 'ra': KIC Right Ascension\n",
    "* 'dec': KIC Declination\n",
    "* 'koi_kepmag': Kepler-band (mag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "dev"
  },
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit ('PythonData': conda)",
   "language": "python",
   "name": "python37564bitpythondataconda93b4aacbe3a94029a49f9aca4966340b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
